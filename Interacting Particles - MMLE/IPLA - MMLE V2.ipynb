{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'experiment_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sg/lxw89kss0x727nlhml9vq0nm0000gn/T/ipykernel_89463/3743639900.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m## Import functions for the experiment :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mexperiment_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPLA_Exp_Functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'experiment_functions'"
     ]
    }
   ],
   "source": [
    "## Importing standards libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "## Importing libraries for the Gaussian Mixture Model\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "\n",
    "## Autograd packages\n",
    "\n",
    "## Convergence metrics\n",
    "\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.stats import entropy # KL-divergence\n",
    "import ot #Optimal Transport\n",
    "\n",
    "\n",
    "## Import functions for the experiment : \n",
    "\n",
    "from experiment_functions import *\n",
    "from IPLA_Exp_Functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we consider a Parametric latent variable models (LVM) in a specific setting. In this context, we will be able to do a fair comparison between several algorithms that aim to estimate the Maximum Marginal Likelihood of the model. \n",
    "\\\\ \\\\\n",
    "Let us consider a generic latent variable model as $p_\\theta(x,y)$, parameterised by $\\theta \\in \\mathbb{R}^{d_\\theta}$, for fixed data $y \\in \\mathbb{R}^{d_y}$, and latent variables $x \\in \\mathbb{R}^{d_x}$. This model is considered for fixed observed data $y$, thus formally we see the statistical model as a real-valued mapping $p_\\theta(x,y) : \\mathbb{R}^{d_x} \\times \\mathbb{R}^{d_\\theta} \\rightarrow \\mathbb{R}$. The task we are interested in is to estimate the parameter $\\theta$ that explains the fixed dataset $y$. Often, this task is achieved via the maximum likelihood estimation (MLE). In accordance with this, in our setting, due to the presence of latent variables, we aim at finding the maximum marginal likelihood estimate (MMLE), more precisely, our problem takes the form\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta^\\ast \\in \\arg \\max_{\\theta \\in \\mathbb{R}^{d_\\theta}} \\log p_\\theta(y),\n",
    "\\end{equation}\n",
    "\n",
    "where $p_\\theta(y) := \\int p_\\theta(x,y) \\, dx$ is the marginal likelihood.\n",
    "\\\\ \n",
    "The main difficulty is that, very often, this integral is intractable. This is where the different algorithms studied appear. \n",
    "\\\\ \\\\\n",
    "With the notation $U(\\theta, x) = -\\log p_\\theta(x,y)$, the $\\theta$-gradient of $\\log p_\\theta(y)$ is given as\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_\\theta \\log p_\\theta(y) = - \\frac{\\int \\nabla_\\theta U(\\theta, x) p_\\theta(x, y) \\, dx}{p_\\theta(y)} = - \\int \\nabla_\\theta U(\\theta, x) p_\\theta(x \\mid y) \\, dx,\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\end{justify}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
