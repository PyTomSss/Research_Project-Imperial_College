{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing standards libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "#import torch\n",
    "\n",
    "## Importing libraries for the Gaussian Mixture Model\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "\n",
    "## Convergence metrics\n",
    "\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.stats import entropy # KL-divergence\n",
    "\n",
    "\n",
    "## Import functions for the experiment : \n",
    "\n",
    "from experiment_functions import *\n",
    "from IPLA_Exp_Functions import *\n",
    "from IPLA_functions_MMLE_V2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMLE Experiment with Banana Distribution\n",
    "\n",
    "In this example, we will work on $ \\mathbb{R}^{dx} $ Let us assume the following “banana” prior:\n",
    "\n",
    "$ p(x) \\propto \\exp\\left(-\\frac{x_1^2}{10} - \\frac{x_2^2}{10} - 2(x_2 - x_1^2)^2\\right), $\n",
    "\n",
    "where $ x \\in \\mathbb{R}^{dx} $ We would like to then use the following likelihood:\n",
    "\n",
    "$ p(y|x) = \\mathcal{N}(y; Hx, \\sigma^2 I), $\n",
    "\n",
    "where $ H \\in \\mathbb{R}^{dx} $ and $ y \\in \\mathbb{R} $ \n",
    "\n",
    "Our first goal is to sample from $ p(x|y) $ efficiently given the parameter $H$. Then, we will proceed to estimate the Maximum Marginal Likelihood of the model, given the observation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_banana(x):\n",
    "\n",
    "    x = -x/5\n",
    "\n",
    "    x[:, 0] += 8 * x[:, 0] * (x[:, 1] - x[:, 0]**2)\n",
    "\n",
    "    x[:, 1] -= 4 * (x[:, 1] - x[:, 0]**2)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_init = np.random.randn(10000, 2)\n",
    "\n",
    "plot_sample_dx(grad_banana(sample_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ULA_banana(sample, nb_iter, step_size, plot = False):\n",
    "\n",
    "    sample_size = sample.shape[0]\n",
    "\n",
    "    dim_var = sample.shape[1]\n",
    "\n",
    "    for i in range(nb_iter) :\n",
    "\n",
    "        grad = grad_banana(sample)\n",
    "\n",
    "        sample -= step_size * grad + np.sqrt(2*step_size) * np.random.randn(sample_size, dim_var) #MOINS Gradient du potentiel\n",
    "    \n",
    "    if plot : \n",
    "\n",
    "        plot_sample_dx(sample, 'Banana Prior')\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_init = np.random.randn(1000, 2)\n",
    "\n",
    "x= ULA_banana(sample_init, 50000, 0.00003)\n",
    "\n",
    "print(f'Nb NaN {np.sum(np.isnan(x))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = np.zeros((1000, 2))\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    grad[i] = grad_banana(np.array([[0.1*i, 0.1*i ], [0.1*i, 0.1*i]]))[0] / np.linalg.norm(np.array([0.1*i, 0.1*i]))\n",
    "    #grad[i] = grad_banana(np.array([[0.1*i, 0.1*i], [0.1*i, 0.1*i]]))[0]\n",
    "\n",
    "plot_sample_dx(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we can use this algo to sample from the prior distribution and generate the observation $y$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_theta = np.array([-1, 1])\n",
    "\n",
    "x_star = ULA_banana(np.random.randn(2, 2), 50000, 0.00003)\n",
    "\n",
    "y_obs = np.dot(true_theta, x_star[0]) + np.random.normal(0, 0.1)\n",
    "\n",
    "y_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now ULA used to sample from posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ULA_post_banana(sample, nb_iter, step_size, theta, y_obs, sigma_y):\n",
    "\n",
    "    sample_size = sample.shape[0]\n",
    "\n",
    "    dim_var = sample.shape[1]\n",
    "\n",
    "    for i in tqdm(range(nb_iter)) :\n",
    "\n",
    "        grad = grad_banana(sample)\n",
    "\n",
    "        grad += (1/sigma_y**2) * (y_obs - theta[:, np.newaxis].T * sample) * theta\n",
    "\n",
    "        sample -= step_size * grad + np.sqrt(2*step_size) * np.random.randn(sample_size, dim_var) #MOINS Gradient du potentiel\n",
    "\n",
    "        if np.sum(np.isnan(sample)) // 2 > 850: \n",
    "            return 'Too much NaN'\n",
    "    \n",
    "    plot_sample_dx(sample, 'Banana Prior')\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instable mais a voir si cela suit la vraie posterior ou pas ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_init = np.random.randn(1000, 2)\n",
    "ULA_post_banana(sample_init, 100000, 0.0000002, true_theta, y_obs, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_star_list = np.array([[1, 1], [-1, 1], [3,2], [5,1], [2,0]])\n",
    "\n",
    "for theta_star in theta_star_list:\n",
    "    \n",
    "    y_obs_list = np.zeros(1000)\n",
    "\n",
    "    for i in tqdm(range(1000)):\n",
    "\n",
    "        x_star = ULA_banana(np.random.randn(2, 2), 20000, 0.00003)\n",
    "\n",
    "        y_obs_list[i] = np.dot(theta_star, x_star[0]) + np.random.normal(0, 0.1)\n",
    "\n",
    "    sns.kdeplot(y_obs_list, fill=True)\n",
    "    plt.title('Estimation de la Densité par Noyau (KDE)')\n",
    "    plt.xlabel('Valeur')\n",
    "    plt.ylabel('Densité')\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
